batch_size: 500  # number of documents to load at once in a chroma collection

paths:
  questions: data/questions_df.csv
  chroma: null   # where to store chroma collections
                        # set to null if you don't want to persist the collections
  corpora: data/datasets/state_of_the_union.md
  experiments: experiments  # where to store experiment results
  wandb: null   # where to store wandb runs
                # set to null if you don't want to use weights and biases

embeddings:
  device: cpu # the environment installed from requirements.txt doesn't have pytorch, just for the sake of consistency
  model_name: sentence-transformers/all-MiniLM-L6-v2  # only supported right now

metrics:
  - recall
  - precision
  # - iou  # also supported

chunk_size:
  # creates a range including the "end" value e.g. [50, 100, 150, ..., 500 (including 500)]
  start: 50
  end: 500
  step: 50

chunk_overlap:
  start: 0
  end: 250
  step: 25

num_chunks:
  start: 1
  end: 10
  step: 1
